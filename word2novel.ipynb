{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gensim\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"ruwikiruscorpora_0_300_20.bin.gz\", binary=True)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "punct = re.compile('^(.*?)([а-яА-ЯёЁ-]+)(.*?)$')\n",
    "capit = re.compile('^[А-Я]+$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pth_source = 'books_before/'\n",
    "lst = os.listdir(pth_source)\n",
    "\n",
    "pth_result = 'books_after/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cotags = {'ADJF':'ADJ', # pymorphy2: word2vec \n",
    "'ADJS' : 'ADJ', \n",
    "'ADVB' : 'ADV', \n",
    "'COMP' : 'ADV', \n",
    "'GRND' : 'VERB', \n",
    "'INFN' : 'VERB', \n",
    "'NOUN' : 'NOUN', \n",
    "'PRED' : 'ADV', \n",
    "'PRTF' : 'ADJ', \n",
    "'PRTS' : 'VERB', \n",
    "'VERB' : 'VERB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(ord('А'))\n",
    "#print(ord('Я'))\n",
    "#print(ord('Ё'))\n",
    "capit_letters = [chr(x) for x in range(1040,1072)] + ['Ё']\n",
    "#print(capit_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### todo\n",
    "\n",
    "* ~~capitalize~~\n",
    "* ~~pos detection~~\n",
    "* ~~cashing of word2vec queries~~\n",
    "* ~~1st form extraction from pymorphy2 parse of word2vec response~~\n",
    "* ~~pos matching for most similar words~~\n",
    "* ~~names detection and excluding from the process~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_neighbour(word, pos):\n",
    "    lex = word + '_' + cotags[pos]\n",
    "    if lex in model:\n",
    "        neighbs = model.most_similar([lex])\n",
    "        for nei in neighbs:\n",
    "            lex_n, ps_n = nei[0].split('_')\n",
    "            if cotags[pos] == ps_n:\n",
    "                return lex_n\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flection(lex_neighb, tags):\n",
    "    tags = str(tags)\n",
    "    tags = re.sub(',[AGQSPMa-z-]+? ', ',', tags)\n",
    "    tags = tags.replace(\"impf,\", \"\")\n",
    "    #tags = tags.replace(\" masc\", \",masc\")\n",
    "    tags = re.sub('([A-Z]) (plur|masc|femn|neut|inan)', '\\\\1,\\\\2', tags)\n",
    "    #tags = tags.replace(\"ADJF plur\", \"ADJF\")\n",
    "    tags = tags.split(',')\n",
    "    tags = frozenset(tags)\n",
    "    #print (lex_neighb, tags)\n",
    "    prep_for_gen = morph.parse(lex_neighb)\n",
    "    ana_array = []\n",
    "    for ana in prep_for_gen:\n",
    "        if ana.normal_form == lex_neighb:\n",
    "            ana_array.append(ana)\n",
    "    for ana in ana_array:\n",
    "        flect = ana.inflect(tags)\n",
    "        if flect:\n",
    "            word_to_replace = flect.word\n",
    "            #print(word_to_replace)\n",
    "            return word_to_replace\n",
    "    return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('теплый_ADJ', 0.6912842392921448),\n",
       " ('холод_NOUN', 0.6222048997879028),\n",
       " ('прохладный_ADJ', 0.6178681254386902),\n",
       " ('влажный_ADJ', 0.6009092926979065),\n",
       " ('жаркий_ADJ', 0.5878441333770752),\n",
       " ('горячий_ADJ', 0.5811808109283447),\n",
       " ('ледяной_ADJ', 0.5738131999969482),\n",
       " ('сухой_ADJ', 0.5681436657905579),\n",
       " ('сырой_ADJ', 0.5447033643722534),\n",
       " ('холодно_ADV', 0.5389620661735535)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(['холодный_ADJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FathersAndSons.txt\n",
      "MasterAndMargarita.txt\n",
      "EugeneOnegin.txt\n",
      "CrimeAndPunishment.txt\n",
      "WarAndPeace.txt\n"
     ]
    }
   ],
   "source": [
    "cash_neighb = {}\n",
    "\n",
    "for fl in lst:\n",
    "    print (fl)\n",
    "    i = 0\n",
    "    f = open(pth_source + fl, 'r', encoding='utf-8')\n",
    "    fw = open(pth_result + fl, 'w', encoding='utf-8')\n",
    "    for line in f:\n",
    "        new_line = []\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            struct = punct.findall(word)\n",
    "            if struct:\n",
    "                struct = struct[0]\n",
    "            else:\n",
    "                new_line.append(word)\n",
    "                continue\n",
    "            #print (struct)\n",
    "            wordform = struct[1]\n",
    "            if wordform:\n",
    "                if capit.search(wordform):\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                else:\n",
    "                    if wordform[0] in capit_letters:\n",
    "                        capit_flag = 1\n",
    "                    else:\n",
    "                        capit_flag = 0\n",
    "                parse_result = morph.parse(wordform)[0]\n",
    "                if 'Name' in parse_result.tag or 'Patr' in parse_result.tag:\n",
    "                    new_line.append(word)\n",
    "                    continue\n",
    "                pos_flag = 0\n",
    "                for tg in cotags:\n",
    "                    if tg in parse_result.tag:\n",
    "                        pos_flag = 1\n",
    "                        lex = parse_result.normal_form\n",
    "                        pos_tag = parse_result.tag.POS\n",
    "                        if (lex, pos_tag) in cash_neighb:\n",
    "                            lex_neighb = cash_neighb[(lex, pos_tag)]\n",
    "                        else:\n",
    "                            lex_neighb = search_neighbour(lex, pos_tag)\n",
    "                            cash_neighb[(lex, pos_tag)] = lex_neighb\n",
    "                        if not lex_neighb:\n",
    "                            new_line.append(word)\n",
    "                            break\n",
    "                        else:\n",
    "                            if pos_tag == 'NOUN':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                    else:\n",
    "                                        new_line.append(word)\n",
    "                                    \n",
    "                            elif pos_tag == 'ADJF':\n",
    "                                if parse_result.tag.case == 'nomn' and parse_result.tag.number == 'sing':\n",
    "                                    if capit_flag == 1:\n",
    "                                        lex_neighb = lex_neighb.capitalize()\n",
    "                                    new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                else:\n",
    "                                    word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                    if word_to_replace:\n",
    "                                        if capit_flag == 1:\n",
    "                                            word_to_replace = word_to_replace.capitalize()\n",
    "                                        new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                    else:\n",
    "                                        new_line.append(word)\n",
    "                            \n",
    "                            elif pos_tag == 'INFN':\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                            \n",
    "                            elif pos_tag in ['ADVB', 'COMP', 'PRED']:\n",
    "                                if capit_flag == 1:\n",
    "                                    lex_neighb = lex_neighb.capitalize()\n",
    "                                new_line.append(struct[0] + lex_neighb + struct[2])\n",
    "                                \n",
    "                            else:\n",
    "                                word_to_replace = flection(lex_neighb, parse_result.tag)\n",
    "                                if word_to_replace:\n",
    "                                    if capit_flag == 1:\n",
    "                                        word_to_replace = word_to_replace.capitalize()\n",
    "                                    new_line.append(struct[0] + word_to_replace + struct[2])\n",
    "                                else:\n",
    "                                    new_line.append(word)\n",
    "                        break\n",
    "                    #else:\n",
    "                        #new_line.append(word)\n",
    "                if pos_flag == 0:\n",
    "                    new_line.append(word)\n",
    "            \n",
    "            else:\n",
    "                new_line.append(''.join(struct))\n",
    "        line_replace = ' '.join(new_line)\n",
    "        fw.write(line_replace + '\\n')\n",
    "    f.close()\n",
    "    fw.close()\n",
    "            \n",
    "            \n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
